# Neural-Network-Python
Feed-forward Neural network implementation in python - using numpy library.


# Functions Usage

- [Activation Values](https://github.com/techcentaur/Neural-Network-Python/blob/master/activation_values.py)

    The file contain a function which will return the activation values in output of an input layer


- [Back Propagation](https://github.com/techcentaur/Neural-Network-Python/blob/master/back_propagation.py)

    The file contain a function which will return a tuple as the gradient for the cost function, according to the famous back propagation algorithm.

- [Cost Derivative](https://github.com/techcentaur/Neural-Network-Python/blob/master/cost_derivative.py)

    This file contain a function which returns the vector of partial derivatives.

- [Sigmoid Functions](https://github.com/techcentaur/Neural-Network-Python/blob/master/sigmoid_functions.py)

    This file contains 2 functions:

`sigmoid.py`

    It returns the sigmoid function

`sigmoid_prime`

    It returns the derivative of sigmoid function

- [Stochastic Gradient Descent](https://github.com/techcentaur/Neural-Network-Python/blob/master/stochastic_gradient_descent.py)

    This File contains a function which will train Neural Network using mini-batchs.

- [Update Mini Batch](https://github.com/techcentaur/Neural-Network-Python/blob/master/update_mini_batch.py)

    The File contains a function which will update the network's weights and biases by applying gradient descent using backpropagation to a single mini batch.


## [Neural Network](https://github.com/techcentaur/Neural-Network-Python/blob/master/neural_network.py)

This File contains a Class 'Network' which consists of all the above mentioned functions and appropriate function calls.


#### Thanks to - 

- Numpy library
- Michael Nielson